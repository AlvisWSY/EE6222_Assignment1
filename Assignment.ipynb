{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.spatial import distance\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset and describe data distribution (Wine Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 类别分布\n",
    "def class_distribution(df):\n",
    "    print(\"\\n### Class Distribution ###\")\n",
    "    class_counts = df['label'].value_counts()\n",
    "    print(class_counts)\n",
    "    \n",
    "    # 可视化类别分布\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    class_counts.plot(kind='bar', title='Class Distribution')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.show()\n",
    "\n",
    "# 2. 描述性统计和特征分布\n",
    "def descriptive_statistics_and_distribution(df, features):\n",
    "    print(\"\\n### Descriptive Statistics ###\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\n### Feature Distributions ###\")\n",
    "    # 设置子图的网格大小，n行3列，每个子图对应一个特征\n",
    "    n = len(features)\n",
    "    rows = (n + 2) // 3  # 计算行数，确保能放下所有子图\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))  # 创建子图\n",
    "    axes = axes.flatten()  # 将子图数组展平成1维数组，方便遍历\n",
    "    \n",
    "    # 遍历每个特征并创建子图\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]  # 选择当前子图\n",
    "        df[feature].hist(bins=20, ax=ax)\n",
    "        ax.set_title(f'Distribution of {feature}')\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Frequency')\n",
    "    \n",
    "    # 删除多余的空白子图\n",
    "    for i in range(n, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    # 调整布局，避免子图重叠\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. 箱线图\n",
    "def boxplot_of_features(df, features):\n",
    "    print(\"\\n### Boxplots of Features by Class ###\")\n",
    "    \n",
    "    # 设置子图的网格大小，n行3列，每个子图对应一个特征\n",
    "    n = len(features)\n",
    "    rows = (n + 2) // 3  # 计算行数，确保能放下所有子图\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))  # 创建子图\n",
    "    axes = axes.flatten()  # 将子图数组展平成1维数组，方便遍历\n",
    "    \n",
    "    # 遍历每个特征并创建子图\n",
    "    for i, feature in enumerate(features):\n",
    "        ax = axes[i]  # 选择当前子图\n",
    "        df.boxplot(column=feature, by='label', ax=ax)\n",
    "        ax.set_title(f'{feature} Distribution by Class')\n",
    "        ax.set_xlabel('Class')\n",
    "        ax.set_ylabel(feature)\n",
    "    \n",
    "    # 删除多余的空白子图\n",
    "    for i in range(n, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    # 调整布局，避免子图重叠\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('')  # 去掉默认的子图标题\n",
    "    plt.show()\n",
    "\n",
    "# 4. 相关性分析\n",
    "def correlation_analysis(df):\n",
    "    print(\"\\n### Correlation Matrix ###\")\n",
    "    \n",
    "    # 计算相关性矩阵\n",
    "    correlation_matrix = df.corr()\n",
    "    print(correlation_matrix)\n",
    "    \n",
    "    # 可视化相关性矩阵\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(data_path):\n",
    "    \"\"\"\n",
    "    Comprehensive description function that calls individual functions to:\n",
    "    1. Show class distribution.\n",
    "    2. Provide descriptive statistics for each feature.\n",
    "    3. Display boxplots for each feature, comparing distributions by class.\n",
    "    4. Analyze and visualize the correlation between features.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_path: str, path to the CSV file of the dataset.\n",
    "    \n",
    "    The features are automatically extracted from the CSV's first row, excluding the 'label' column.\n",
    "    \"\"\"\n",
    "    # 加载数据\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # 自动提取特征列表（排除 label 列）\n",
    "    features = [col for col in df.columns if col != 'label']\n",
    "    \n",
    "    # 调用各个功能函数\n",
    "    print(\"\\nStep 1: Class Distribution\")\n",
    "    class_distribution(df)          # 类别分布\n",
    "    \n",
    "    print(\"\\nStep 2: Descriptive Statistics and Feature Distribution\")\n",
    "    descriptive_statistics_and_distribution(df, features) # 描述性统计和特征分布\n",
    "    \n",
    "    print(\"\\nStep 3: Boxplots of Features by Class\")\n",
    "    boxplot_of_features(df, features)  # 特征箱线图\n",
    "    \n",
    "    print(\"\\nStep 4: Correlation Analysis\")\n",
    "    correlation_analysis(df)        # 相关性分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load data and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "data_path = 'data/wine_data.csv'\n",
    "describe_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df_wine = pd.read_csv('data/wine_data.csv')\n",
    "\n",
    "# 假设 df_wine 是包含特征和标签的 DataFrame，标签列为 'label'\n",
    "X = df_wine.drop('label', axis=1)  # 特征数据\n",
    "y = df_wine['label']  # 标签\n",
    "\n",
    "# 1. 进行过采样\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_wine = smote.fit_resample(X, y)\n",
    "\n",
    "# 2. 进行归一化\n",
    "scaler = StandardScaler()\n",
    "X_wine = scaler.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# 获取数据和标签\n",
    "X_mnist, y_mnist = mnist['data'], mnist['target']\n",
    "\n",
    "# 数据归一化\n",
    "X_mnist = X_mnist.astype('float32') / 255.0\n",
    "\n",
    "# 查看数据集的形状\n",
    "print(f\"数据集形状: {X_mnist.shape}, 标签形状: {y_mnist.shape}\")\n",
    "\n",
    "# 将标签转换为整型（默认是字符串类型）\n",
    "y = y.astype(int)\n",
    "\n",
    "# 数据集已经是展平形式，每个图像有784个特征\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA and LDA approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数化的 PCA 结果和可视化函数\n",
    "def visualize_3d_pca(X_pca, y_resampled, title=\"PCA 3D 可视化\"):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 绘制 3D 散点图，使用标签进行着色\n",
    "    sc = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=y_resampled, cmap='viridis', edgecolor='k')\n",
    "\n",
    "    # 设置坐标轴标签\n",
    "    ax.set_xlabel('第一个主成分')\n",
    "    ax.set_ylabel('第二个主成分')\n",
    "    ax.set_zlabel('第三个主成分')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # 添加颜色条（显示类别标签）\n",
    "    plt.colorbar(sc, label='类别标签')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 进行 PCA 降维\n",
    "pca3 = PCA(n_components=3)\n",
    "pca4 = PCA(n_components=4)\n",
    "pca95 = PCA(n_components=0.95)\n",
    "\n",
    "X_wine_pca3 = pca3.fit_transform(X_wine)\n",
    "X_wine_pca4 = pca4.fit_transform(X_wine)\n",
    "X_wine_pca95 = pca95.fit_transform(X_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用可视化函数，分别展示不同 PCA 结果的 3D 散点图\n",
    "visualize_3d_pca(X_wine_pca3, y_wine, title=\"PCA 3D 可视化 - 3 主成分\")\n",
    "visualize_3d_pca(X_wine_pca4, y_wine, title=\"PCA 3D 可视化 - 4 主成分 (选择前三个维度)\")\n",
    "visualize_3d_pca(X_wine_pca95[:, :3], y_wine, title=\"PCA 3D 可视化 - 0.95 方差保留 (选择前三个维度)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist_pca95 = pca95.fit_transform(X_mnist)\n",
    "\n",
    "# 调用可视化函数，展示 MNIST 数据集的 3D PCA 结果\n",
    "visualize_3d_pca(X_mnist_pca95[:, :3], y_mnist, title=\"MNIST 数据集 PCA 3D 可视化 - 0.95 方差保留 (选择前三个维度)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Classifier\n",
    "\n",
    "class MahalanobisClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_means = {}\n",
    "        self.class_cov_inv = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        classes = np.unique(y)\n",
    "        for cls in classes:\n",
    "            X_class = X[y == cls]\n",
    "            self.class_means[cls] = np.mean(X_class, axis=0)\n",
    "            cov_matrix = np.cov(X_class, rowvar=False)\n",
    "            self.class_cov_inv[cls] = np.linalg.inv(cov_matrix)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            distances = []\n",
    "            for cls in self.class_means:\n",
    "                mean = self.class_means[cls]\n",
    "                cov_inv = self.class_cov_inv[cls]\n",
    "                d = distance.mahalanobis(x, mean, cov_inv)\n",
    "                distances.append((cls, d))\n",
    "            y_pred.append(min(distances, key=lambda t: t[1])[0])\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier\n",
    "\n",
    "class LinearClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbor Classifier\n",
    "\n",
    "class NearestNeighborClassifier:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classifiers(X, y, classifiers: dict, test_size=0.2):\n",
    "    '''\n",
    "    # 使用示例\n",
    "    classifiers = {\n",
    "        \"Mahalanobis\": MahalanobisClassifier(),\n",
    "        \"Linear\": LinearClassifier(),\n",
    "        \"Nearest Neighbor\": NearestNeighborClassifier()\n",
    "    }\n",
    "    # 对于数据集：\n",
    "    compare_classifiers(X, y, classifiers)\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    results = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results[name] = acc\n",
    "        print(f\"{name} 分类器的准确性: {acc:.4f}\")\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
